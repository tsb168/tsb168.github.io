<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Project 5: Fun With Diffusion Models!</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="840ff514-c18e-4529-9247-0e1022da7f55" class="page sans"><header><h1 class="page-title">Project 5: <strong>Fun With Diffusion Models!</strong></h1><p class="page-description"></p></header><div class="page-body"><p id="13ff94b9-c68f-804c-b879-e0424124ad52" class="">Tej Bade, tbade12@berkeley.edu</p><nav id="13ff94b9-c68f-8001-b0d4-f603a6402545" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#13ff94b9-c68f-80a0-8721-f6983faeea94">Part A: The Power of Diffusion Models</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#13ff94b9-c68f-8090-990f-e5a161245630">0. Setup </a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#13ff94b9-c68f-8043-b81c-e5752dbb7416">1. Sampling Loops</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-80ce-8bb8-e6cd0d6ae9cb">1.1 Implementing the forward process</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-80dc-9f4f-c381992064c9">1.2 Classical Denoising</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#9637c673-babb-4780-a0a5-91638e7e6c4a">1.3 Implementing One Step Denoising</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#e2e156e5-5e5e-4dba-a12d-406cb559fdad">1.4 Implementing Iterative Denoising</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-8028-8ff3-ceaa4bc4df8d">1.5 Diffusion Model Sampling</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-809a-9270-d62871287fbe">1.6 Classifier-Free Guidance</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-8035-853a-db9e849d4ef1">1.7 Image-to-Image Translation</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-8009-b4b3-e0f1643bed1c">1.7.1 Editing Hand-Drawn and Web Images</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-80ec-a61a-ff186b03f7d8">1.7.2 Inpainting</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-8003-911a-c8c9f21a40d4">1.7.3 Text-Conditioned Image-to-Image Translation</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-806f-af65-c307bb279236">1.8 Visual Anagrams</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#13ff94b9-c68f-8084-8e23-fee065fb2b85">1.9 Hybrid Images</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#13ff94b9-c68f-80a6-bde1-d6b83dba191a">Part B: Diffusion Models from Scratch</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#144f94b9-c68f-800a-ae90-caa4cd4935cc">Part 1: Training a Single-Step Denoising UNet</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#145f94b9-c68f-8033-a13d-dd9d16d680a3">Part 2: Training a Diffusion Model</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#145f94b9-c68f-8092-be12-d40fc7234c31">Adding Time-Conditioning to UNet</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#145f94b9-c68f-801a-bfef-df74989916ca">Adding Class-Conditioning to UNet</a></div></nav><h1 id="13ff94b9-c68f-80a0-8721-f6983faeea94" class="">Part A: The Power of Diffusion Models</h1><h2 id="13ff94b9-c68f-8090-990f-e5a161245630" class="">0. Setup </h2><p id="13ff94b9-c68f-8052-9315-c41391f86d3d" class="">In this project we use the DeepFloyd IF diffusion model, which has two stages. We feed in three prompts and generate images for the three prompts. I used random seed 1234 (which will be the seed used for the remainder of the project). I set the number of inference steps to 20. The results are shown below. </p><figure id="144f94b9-c68f-801f-966c-cdea6c2e9e60" class="image"><a href="media/Screenshot_2024-11-20_at_2.45.34_AM.png"><img style="width:707.9921875px" src="media/Screenshot_2024-11-20_at_2.45.34_AM.png"/></a></figure><p id="13ff94b9-c68f-80fa-aeac-fecdac3af568" class="">The results are of good quality and fit the prompt well. I then changed the number of inference steps to 5. The following images show the sampled images with num_inference_steps=5.</p><figure id="144f94b9-c68f-80e3-9d0b-c3784edfded1" class="image"><a href="media/Screenshot_2024-11-20_at_2.45.52_AM.png"><img style="width:707.984375px" src="media/Screenshot_2024-11-20_at_2.45.52_AM.png"/></a></figure><p id="13ff94b9-c68f-80f0-8d7f-fa94df8c109f" class="">Decreasing the number of inference steps to 5 has made the output have less quality and more noise. </p><h2 id="13ff94b9-c68f-8043-b81c-e5752dbb7416" class="">1. Sampling Loops</h2><p id="144f94b9-c68f-8025-bfee-d043d754d901" class="">For this section we use the following test image. </p><figure id="144f94b9-c68f-80fa-9928-ff38761311f5" class="image"><a href="media/campanile.jpg"><img style="width:192px" src="media/campanile.jpg"/></a></figure><h3 id="13ff94b9-c68f-80ce-8bb8-e6cd0d6ae9cb" class="">1.1 Implementing the forward process</h3><p id="13ff94b9-c68f-800d-b41a-c30b40825e1b" class="">We first implement the forward process, which means taking a clean image and adding noise to it. Given a clean image <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> and a timestep <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span><span>﻿</span></span>, we can generate a noisy image <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> by the following equation</p><figure id="144f94b9-c68f-8060-95b3-e67f52df2e96" class="image"><a href="media/Screenshot_2024-11-19_at_4.29.55_PM.png"><img style="width:480px" src="media/Screenshot_2024-11-19_at_4.29.55_PM.png"/></a></figure><p id="144f94b9-c68f-80ff-8ebf-c23e3b926944" class="">for precomputed “alpha_bar” values. The results of the test image with t = 250, 500, 750 are shown below. </p><figure id="144f94b9-c68f-802e-814b-ed386f792234" class="image"><a href="media/Screenshot_2024-11-20_at_2.59.35_AM.png"><img style="width:492px" src="media/Screenshot_2024-11-20_at_2.59.35_AM.png"/></a></figure><h3 id="13ff94b9-c68f-80dc-9f4f-c381992064c9" class="">1.2 Classical Denoising</h3><p id="144f94b9-c68f-8070-9ac2-fb58d7a20c65" class="">One classical method for denoising the images is to use a Gaussian blur. For t = 250, 500, 750 we use (5, 1), (7, 1), and (7, 2) as our (kernel size, sigma) values respectively. </p><figure id="144f94b9-c68f-8064-a321-e115bd6ff7b9" class="image"><a href="media/Screenshot_2024-11-20_at_3.00.43_AM.png"><img style="width:480px" src="media/Screenshot_2024-11-20_at_3.00.43_AM.png"/></a></figure><div id="144f94b9-c68f-8068-9666-cf0425f127f9" class="column-list"><div id="9025eb85-87b9-4262-82c7-1f355febc550" style="width:50%" class="column"><h3 id="9637c673-babb-4780-a0a5-91638e7e6c4a" class="">1.3 Implementing One Step Denoising</h3><p id="144f94b9-c68f-8014-b0e0-eb6b683e4de9" class="">We can use our equation in section 1.1 to solve for <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> given <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> and <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span><span>﻿</span></span>. This is called one-step denoising. This gives us the following denoised images for t = 250, 500, 750</p><figure id="144f94b9-c68f-80e8-bd55-eadec3ee7165" class="image"><a href="media/Screenshot_2024-11-20_at_3.03.25_AM.png"><img style="width:336px" src="media/Screenshot_2024-11-20_at_3.03.25_AM.png"/></a></figure></div><div id="b0f25671-7ae5-4810-84fd-62475321a7e6" style="width:50%" class="column"><h3 id="e2e156e5-5e5e-4dba-a12d-406cb559fdad" class="">1.4 Implementing Iterative Denoising</h3><p id="144f94b9-c68f-801a-87b6-eef02f7cf781" class="">Instead of denoising all at once, we can use the following equation to iteratively denoise. </p><figure id="144f94b9-c68f-80cb-9eff-c663384c4f8f" class="image"><a href="media/Screenshot_2024-11-20_at_5.50.20_AM.png"><img style="width:432.9921875px" src="media/Screenshot_2024-11-20_at_5.50.20_AM.png"/></a></figure><p id="144f94b9-c68f-80a9-8aa0-c840cb564b8b" class="">Using this algorithm, we get the following results for every 5th loop of the denoising process. At the end is the final predicted image using this and the past two methods. </p><figure id="144f94b9-c68f-801a-90a9-c6e6c343922b" class="image"><a href="media/Screenshot_2024-11-20_at_3.04.36_AM.png"><img style="width:288px" src="media/Screenshot_2024-11-20_at_3.04.36_AM.png"/></a></figure></div></div><h3 id="13ff94b9-c68f-8028-8ff3-ceaa4bc4df8d" class="">1.5 Diffusion Model Sampling</h3><p id="144f94b9-c68f-806c-a1e7-e9ca94aa5a12" class="">We can use our method of iteratively denoising in section 1.4 to generate images from scratch. To do this, we pass in random noise into our method. 5 samples are shown below. </p><figure id="144f94b9-c68f-8004-ad1f-eb31fe4a3e1d" class="image"><a href="media/Screenshot_2024-11-20_at_3.13.01_AM.png"><img style="width:707.984375px" src="media/Screenshot_2024-11-20_at_3.13.01_AM.png"/></a></figure><h3 id="13ff94b9-c68f-809a-9270-d62871287fbe" class="">1.6 Classifier-Free Guidance</h3><p id="144f94b9-c68f-80b7-b214-ceb3f1d06058" class="">In order to improve image quality, we can pass in the embeddings for the prompt &quot;a high quality photo.” We can find noise estimates when we condition and don’t condition on the prompt and then find a final noise estimate with equation below (gamma is set to 7). </p><figure id="144f94b9-c68f-805b-a868-c749d80aacbc" class="image"><a href="media/Screenshot_2024-11-20_at_6.00.05_AM.png"><img style="width:288px" src="media/Screenshot_2024-11-20_at_6.00.05_AM.png"/></a></figure><p id="144f94b9-c68f-80d4-8219-dc727e139d17" class="">This method gave me the following 5 sampled images which are indeed higher quality photos. </p><figure id="144f94b9-c68f-80ef-b726-f8ba080a8776" class="image"><a href="media/Screenshot_2024-11-20_at_3.13.57_AM.png"><img style="width:707.9921875px" src="media/Screenshot_2024-11-20_at_3.13.57_AM.png"/></a></figure><h3 id="13ff94b9-c68f-8035-853a-db9e849d4ef1" class="">1.7 Image-to-Image Translation</h3><p id="144f94b9-c68f-80e5-967b-ef1f63587186" class="">In this part, we take an image, noise it a little, and run the classifier-free guidance method from above with the &quot;a high quality photo” prompt using starting indices of [1, 3, 5, 7, 10, 20]. This effectively creates a series of images that gradually becomes closer to the original. </p><figure id="144f94b9-c68f-80dc-94b3-ee22e69e71e6" class="image"><a href="media/Screenshot_2024-11-20_at_4.10.22_AM.png"><img style="width:707.984375px" src="media/Screenshot_2024-11-20_at_4.10.22_AM.png"/></a></figure><p id="144f94b9-c68f-8057-b5cb-dd37dc272b49" class="">I also found two other images from the web to test with. </p><div id="144f94b9-c68f-8008-957d-f3887b6c2c59" class="column-list"><div id="144f94b9-c68f-803a-b3e4-f9853577c0cf" style="width:50%" class="column"><figure id="144f94b9-c68f-80ea-8588-edd5053404b0" class="image"><a href="media/lake.jpg"><img style="width:288px" src="media/lake.jpg"/></a></figure></div><div id="144f94b9-c68f-8033-960d-ecd12bfd28d5" style="width:50%" class="column"><figure id="144f94b9-c68f-808b-a715-c197562fbc46" class="image"><a href="media/bottles.jpg"><img style="width:288px" src="media/bottles.jpg"/></a></figure></div></div><p id="144f94b9-c68f-8067-b0da-e98b58d54d1f" class="">The same process above was applied to these images. </p><figure id="144f94b9-c68f-8014-9222-d76ee92bce2e" class="image"><a href="media/Screenshot_2024-11-20_at_4.12.36_AM.png"><img style="width:707.984375px" src="media/Screenshot_2024-11-20_at_4.12.36_AM.png"/></a></figure><h3 id="13ff94b9-c68f-8009-b4b3-e0f1643bed1c" class="">1.7.1 Editing Hand-Drawn and Web Images</h3><p id="144f94b9-c68f-80eb-b46f-e35e548b462e" class="">We can apply the process above to nonrealistic images too. Shown below are the edits for a web image.  </p><div id="144f94b9-c68f-8057-ac0a-d8fb181e5766" class="column-list"><div id="144f94b9-c68f-80db-a688-fe912a6692f1" style="width:18.75%" class="column"><figure id="144f94b9-c68f-80a5-8df8-c999b9c487cd" class="image"><a href="media/Screenshot_2024-11-20_at_4.15.38_AM.png"><img style="width:144px" src="media/Screenshot_2024-11-20_at_4.15.38_AM.png"/></a><figcaption>Original </figcaption></figure></div><div id="144f94b9-c68f-8083-9809-e8c89f7b9de2" style="width:81.25%" class="column"><figure id="144f94b9-c68f-8080-8040-facb11d5c72c" class="image"><a href="media/Screenshot_2024-11-20_at_4.14.50_AM.png"><img style="width:384px" src="media/Screenshot_2024-11-20_at_4.14.50_AM.png"/></a><figcaption>“Edited” images</figcaption></figure></div></div><p id="144f94b9-c68f-803f-9eb0-e9aacffc900f" class="">I also created the following hand-drawn images. </p><div id="144f94b9-c68f-801a-a3c2-cc6fd5a774fd" class="column-list"><div id="144f94b9-c68f-806e-88cd-d79894bead17" style="width:50%" class="column"><figure id="144f94b9-c68f-80dd-8bf8-c826cdb522fe" class="image"><a href="media/myImage.png"><img style="width:331px" src="media/myImage.png"/></a></figure></div><div id="144f94b9-c68f-80dd-8dab-d74b7eb76d00" style="width:50%" class="column"><figure id="144f94b9-c68f-8044-a232-f5e28da75ab7" class="image"><a href="media/myImage2.png"><img style="width:331px" src="media/myImage2.png"/></a></figure></div></div><div id="144f94b9-c68f-8067-b8f6-db8f3a10ba4c" class="column-list"><div id="144f94b9-c68f-80d8-b545-ef2e561e3f35" style="width:18.75%" class="column"><figure id="144f94b9-c68f-804a-934e-dcd45d835fe0" class="image"><a href="media/Screenshot_2024-11-20_at_4.17.56_AM.png"><img style="width:124.125px" src="media/Screenshot_2024-11-20_at_4.17.56_AM.png"/></a><figcaption> Original </figcaption></figure></div><div id="144f94b9-c68f-8064-be12-ceb6de71a88e" style="width:81.25%" class="column"><figure id="144f94b9-c68f-8086-b9f0-fa9854703b43" class="image"><a href="media/Screenshot_2024-11-20_at_4.18.23_AM.png"><img style="width:330.9609375px" src="media/Screenshot_2024-11-20_at_4.18.23_AM.png"/></a><figcaption>“Edited” images </figcaption></figure></div></div><div id="144f94b9-c68f-8089-b31c-d34a1b3858b5" class="column-list"><div id="144f94b9-c68f-8021-9181-dde1bbe7aee9" style="width:18.75%" class="column"><figure id="144f94b9-c68f-80af-8b89-fd321f683dee" class="image"><a href="media/Screenshot_2024-11-20_at_4.21.36_AM.png"><img style="width:132px" src="media/Screenshot_2024-11-20_at_4.21.36_AM.png"/></a><figcaption>Original </figcaption></figure></div><div id="144f94b9-c68f-808c-ae53-ca02578f305a" style="width:81.25%" class="column"><figure id="144f94b9-c68f-8031-8ae6-f20289e25a29" class="image"><a href="media/Screenshot_2024-11-20_at_4.21.50_AM.png"><img style="width:579.25px" src="media/Screenshot_2024-11-20_at_4.21.50_AM.png"/></a><figcaption>“Edited” images </figcaption></figure></div></div><h3 id="13ff94b9-c68f-80ec-a61a-ff186b03f7d8" class="">1.7.2 Inpainting</h3><p id="144f94b9-c68f-80d1-9f71-df8b2673e1ae" class="">To implement inpainting, we create a mask <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span></span><span>﻿</span></span> and replace <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> with the following at every timestep. </p><figure id="144f94b9-c68f-80c9-beed-ec70bfb352ee" class="image"><a href="media/Screenshot_2024-11-20_at_6.19.50_AM.png"><img style="width:336px" src="media/Screenshot_2024-11-20_at_6.19.50_AM.png"/></a></figure><p id="145f94b9-c68f-8088-ad59-fd7a9ffca9f4" class="">The masks are shown on the left and the inpainted images are shown on the right. </p><div id="144f94b9-c68f-80da-ac4b-fd3060ffb745" class="column-list"><div id="144f94b9-c68f-80eb-9ce2-ea21ed3922cb" style="width:68.75%" class="column"><figure id="144f94b9-c68f-80d7-acaf-d4831391209e" class="image"><a href="media/Screenshot_2024-11-20_at_5.13.42_AM.png"><img style="width:576px" src="media/Screenshot_2024-11-20_at_5.13.42_AM.png"/></a></figure></div><div id="144f94b9-c68f-8099-b4b9-c9d6642b1bac" style="width:31.25%" class="column"><figure id="144f94b9-c68f-8050-8fb0-fa9e917ad4b0" class="image"><a href="media/Screenshot_2024-11-20_at_5.35.50_AM.png"><img style="width:192px" src="media/Screenshot_2024-11-20_at_5.35.50_AM.png"/></a></figure></div></div><div id="144f94b9-c68f-80a0-851f-ccd4cee4c9c5" class="column-list"><div id="144f94b9-c68f-8018-b4ed-f2ccaa7f224d" style="width:68.75%" class="column"><figure id="144f94b9-c68f-8012-a01f-d8cb5bf4d7d7" class="image"><a href="media/Screenshot_2024-11-20_at_5.36.29_AM.png"><img style="width:432px" src="media/Screenshot_2024-11-20_at_5.36.29_AM.png"/></a></figure></div><div id="144f94b9-c68f-809d-a5d2-dc12ccdba931" style="width:31.25%" class="column"><figure id="144f94b9-c68f-802c-a9c8-fe66779695ad" class="image"><a href="media/Screenshot_2024-11-20_at_5.36.44_AM.png"><img style="width:192px" src="media/Screenshot_2024-11-20_at_5.36.44_AM.png"/></a></figure></div></div><div id="144f94b9-c68f-80c8-82fa-fc101e46bbcf" class="column-list"><div id="144f94b9-c68f-80fa-820e-e90e63de7832" style="width:68.75%" class="column"><figure id="144f94b9-c68f-805e-be8a-c81dc4a3332b" class="image"><a href="media/Screenshot_2024-11-20_at_5.42.59_AM.png"><img style="width:432px" src="media/Screenshot_2024-11-20_at_5.42.59_AM.png"/></a></figure></div><div id="144f94b9-c68f-8033-bb2a-e27c1817e3a4" style="width:31.249999999999993%" class="column"><figure id="144f94b9-c68f-80ae-b7f8-f9a303381657" class="image"><a href="media/Screenshot_2024-11-20_at_5.43.21_AM.png"><img style="width:206.875px" src="media/Screenshot_2024-11-20_at_5.43.21_AM.png"/></a></figure></div></div><h3 id="13ff94b9-c68f-8003-911a-c8c9f21a40d4" class="">1.7.3 Text-Conditioned Image-to-Image Translation</h3><p id="144f94b9-c68f-8053-b5d4-f5d8c85fb57b" class="">In this section we do the same thing from 1.7.1 but change the conditional prompt to “a rocket ship”. This causes the edits to gradually come to the original image but also try to incorporate a rocket ship. </p><figure id="144f94b9-c68f-8056-bee8-f421d7908ef5" class="image"><a href="media/Screenshot_2024-11-20_at_4.32.09_AM.png"><img style="width:707.9765625px" src="media/Screenshot_2024-11-20_at_4.32.09_AM.png"/></a></figure><p id="144f94b9-c68f-80c9-9af9-d675e7aac82f" class="">Shown below is the same process with the rocket ship prompt applied to my two web images. </p><figure id="144f94b9-c68f-803a-9c15-e00f7d79913a" class="image"><a href="media/Screenshot_2024-11-20_at_4.33.16_AM.png"><img style="width:707.9765625px" src="media/Screenshot_2024-11-20_at_4.33.16_AM.png"/></a></figure><h3 id="13ff94b9-c68f-806f-af65-c307bb279236" class="">1.8 Visual Anagrams</h3><p id="144f94b9-c68f-80d0-b16a-d93e5e7e14a0" class="">The following anagrams were created using two conditional prompts, with one prompt being trained on the image when flipped upside down. I created three anagrams. </p><ol type="1" id="13ff94b9-c68f-8020-a3de-f3f799c95992" class="numbered-list" start="1"><li>“an oil painting of people around a campfire” and &quot;an oil painting of an old man”</li></ol><div id="144f94b9-c68f-80a4-9719-f0ab3534a07a" class="column-list"><div id="144f94b9-c68f-80f1-9cb1-c4bcc17bf6b1" style="width:50%" class="column"><figure id="144f94b9-c68f-8010-a4f9-f150cdaf13d2" class="image"><a href="media/Screenshot_2024-11-20_at_4.34.22_AM.png"><img style="width:336px" src="media/Screenshot_2024-11-20_at_4.34.22_AM.png"/></a></figure></div><div id="144f94b9-c68f-80c0-9462-d4f9b591d2e4" style="width:50%" class="column"><figure id="144f94b9-c68f-80ee-8396-cc0af3df0a12" class="image"><a href="media/Screenshot_2024-11-20_at_4.35.22_AM.png"><img style="width:336px" src="media/Screenshot_2024-11-20_at_4.35.22_AM.png"/></a></figure></div></div><ol type="1" id="145f94b9-c68f-8006-bc83-e4952f8294b9" class="numbered-list" start="2"><li>“a photo of the amalfi cost” and “a photo of a man”</li></ol><div id="145f94b9-c68f-8099-8129-c1f96ede3e08" class="column-list"><div id="145f94b9-c68f-80c6-ae1f-d764b902247f" style="width:50%" class="column"><figure id="144f94b9-c68f-8053-ae95-faa2c38b4b75" class="image"><a href="media/Screenshot_2024-11-20_at_4.47.16_AM.png"><img style="width:336px" src="media/Screenshot_2024-11-20_at_4.47.16_AM.png"/></a></figure></div><div id="145f94b9-c68f-80ad-b247-df7e6bf2ce1c" style="width:50%" class="column"><figure id="144f94b9-c68f-805a-bc99-ea7781bbacc2" class="image"><a href="media/Screenshot_2024-11-20_at_4.47.36_AM.png"><img style="width:336px" src="media/Screenshot_2024-11-20_at_4.47.36_AM.png"/></a></figure></div></div><ol type="1" id="145f94b9-c68f-804f-96d6-db96f5f24986" class="numbered-list" start="3"><li>&quot;a photo of a hipster barista” and “a photo of a dog”</li></ol><div id="144f94b9-c68f-802b-a689-cca85d2ee1cb" class="column-list"><div id="144f94b9-c68f-8030-98c3-d92946d28617" style="width:50%" class="column"><figure id="144f94b9-c68f-80dd-91b2-d2478d77fbff" class="image"><a href="media/Screenshot_2024-11-20_at_4.47.48_AM.png"><img style="width:336px" src="media/Screenshot_2024-11-20_at_4.47.48_AM.png"/></a></figure></div><div id="144f94b9-c68f-803b-be98-c3e43f6c25bd" style="width:50%" class="column"><figure id="144f94b9-c68f-80c3-b90f-d20bc19df8bf" class="image"><a href="media/Screenshot_2024-11-20_at_4.48.26_AM.png"><img style="width:336px" src="media/Screenshot_2024-11-20_at_4.48.26_AM.png"/></a></figure></div></div><h3 id="13ff94b9-c68f-8084-8e23-fee065fb2b85" class="">1.9 Hybrid Images</h3><p id="13ff94b9-c68f-8075-a9fd-d0d692c7dc81" class="">Finally, we can create hybrid images, which show one prompt close up and another from farther away. The captions for the images show the “farther away” prompt first and the “close up” prompt second. </p><div id="144f94b9-c68f-80bc-a336-c81278b70a02" class="column-list"><div id="144f94b9-c68f-80c7-842e-c3f526d2e156" style="width:33.333333333333336%" class="column"><figure id="144f94b9-c68f-8077-943d-c86f502807aa" class="image"><a href="media/Screenshot_2024-11-20_at_4.55.58_AM.png"><img style="width:205.328125px" src="media/Screenshot_2024-11-20_at_4.55.58_AM.png"/></a><figcaption>“a lithograph of a skull” and “a lithograph of waterfalls”</figcaption></figure></div><div id="144f94b9-c68f-80bc-a4c9-d3e4098ccb30" style="width:33.333333333333336%" class="column"><figure id="144f94b9-c68f-8052-9e4e-d18e0010dbed" class="image"><a href="media/Screenshot_2024-11-20_at_5.09.27_AM.png"><img style="width:288px" src="media/Screenshot_2024-11-20_at_5.09.27_AM.png"/></a><figcaption>&quot;an oil painting of a snowy mountain village” and &quot;an oil painting of people around a campfire”</figcaption></figure></div><div id="144f94b9-c68f-80a5-8bbc-c21f4782d518" style="width:33.33333333333333%" class="column"><figure id="144f94b9-c68f-80d5-a7f0-d02768165b43" class="image"><a href="media/Screenshot_2024-11-20_at_5.09.53_AM.png"><img style="width:240px" src="media/Screenshot_2024-11-20_at_5.09.53_AM.png"/></a><figcaption>“a rocket ship” and “a pencil”</figcaption></figure></div></div><h1 id="13ff94b9-c68f-80a6-bde1-d6b83dba191a" class="">Part B: Diffusion Models from Scratch</h1><h2 id="144f94b9-c68f-800a-ae90-caa4cd4935cc" class="">Part 1: Training a Single-Step Denoising UNet</h2><p id="145f94b9-c68f-80e8-8c50-d28c8f3cde6f" class="">In this section, we build an Unconditional UNet from scratch. We use the MNIST dataset and generate training data pairs by noising the images with the following equation.</p><figure id="145f94b9-c68f-8058-adc2-cd8aeb251805" class="image"><a href="media/Screenshot_2024-11-20_at_11.25.54_PM.png"><img style="width:288px" src="media/Screenshot_2024-11-20_at_11.25.54_PM.png"/></a></figure><p id="145f94b9-c68f-801a-940f-d49609a1e4a9" class="">Shown below are a few MNIST digits with differing levels of noise. </p><figure id="146f94b9-c68f-801d-80e0-dad924a242e3" class="image"><a href="media/mnist_noise_(1).jpg"><img style="width:708px" src="media/mnist_noise_(1).jpg"/></a></figure><p id="145f94b9-c68f-800a-bbed-ee44f2b8165a" class="">We then train the UNet on the dataset using an Adam optimizer with learning rate 1e-4. The sigma used for this process is 0.5. </p><figure id="146f94b9-c68f-800b-b947-d1d754aa6c95" class="image"><a href="media/uncond_train_loss_(1).jpg"><img style="width:708px" src="media/uncond_train_loss_(1).jpg"/></a></figure><p id="145f94b9-c68f-806e-aad0-d2e4df420d86" class="">I checkpointed the model during the first and fifth epochs so we can visualize how well the model denoises at these stages. I visualized the noised and denoised images for epoch 1 and 5. </p><figure id="146f94b9-c68f-80d1-8a62-e8ab807b3063" class="image"><a href="media/uncond_epoch_1_(3).jpg"><img style="width:708px" src="media/uncond_epoch_1_(3).jpg"/></a></figure><figure id="146f94b9-c68f-8040-aa88-d4f0f87af630" class="image"><a href="media/uncond_epoch_5_(2).jpg"><img style="width:708px" src="media/uncond_epoch_5_(2).jpg"/></a></figure><p id="145f94b9-c68f-807c-9ca4-f80fed7f0206" class="">We use sigma = 0.5 for training so we can see how well the model performs for images of different sigma values. </p><figure id="146f94b9-c68f-80f5-b577-c15765a01c61" class="image"><a href="media/uncond_out_of_distribution_(1).jpg"><img style="width:708px" src="media/uncond_out_of_distribution_(1).jpg"/></a></figure><h2 id="145f94b9-c68f-8033-a13d-dd9d16d680a3" class="">Part 2: Training a Diffusion Model</h2><h3 id="145f94b9-c68f-8092-be12-d40fc7234c31" class="">Adding Time-Conditioning to UNet</h3><p id="145f94b9-c68f-8096-9308-d9b12bbe8bfa" class="">We now train a UNet to iteratively denoise an image by injecting a scalar t into our neural network pipeline. Using an Adam optimizer with an initial learning rate of 1e-3 and an exponential learning rate decay scheduler, we train this new model on our dataset. Shown below are the losses for each step. </p><figure id="145f94b9-c68f-8061-aa99-eb16cc3a7a95" class="image"><a href="media/time_cond_losses.jpg"><img style="width:707.9921875px" src="media/time_cond_losses.jpg"/></a></figure><p id="145f94b9-c68f-80fc-85e9-c4b5a3decf9f" class="">We can now use the model to sample images by passing in random noise. I sampled 40 images using the model state from epoch 5 and 20 of the training process.</p><div id="145f94b9-c68f-804f-88cd-f057a930bbc2" class="column-list"><div id="145f94b9-c68f-804e-b6ba-e798f6dffaff" style="width:50%" class="column"><figure id="145f94b9-c68f-8052-89c1-e94da56431cd" class="image"><a href="media/time_cond_epoch_5_sample.jpg"><img style="width:384px" src="media/time_cond_epoch_5_sample.jpg"/></a><figcaption>Samples for epoch 5</figcaption></figure></div><div id="145f94b9-c68f-8010-bbf7-f9b21a22594a" style="width:50%" class="column"><figure id="145f94b9-c68f-80f2-ba42-dd7e4b2fd54c" class="image"><a href="media/time_cond_epoch_20_sample.jpg"><img style="width:384px" src="media/time_cond_epoch_20_sample.jpg"/></a><figcaption>Samples for epoch 20</figcaption></figure></div></div><h3 id="145f94b9-c68f-801a-bfef-df74989916ca" class="">Adding Class-Conditioning to UNet</h3><p id="145f94b9-c68f-80f2-b0ff-f8f7633e027a" class="">We know that there are 10 digits or classes so we can use our previous model and condition on class as well. Doing this yields the following plot of loss vs. training step. </p><figure id="145f94b9-c68f-80b5-8296-e9b6c330d960" class="image"><a href="media/class_cond_losses.jpg"><img style="width:707.9921875px" src="media/class_cond_losses.jpg"/></a></figure><p id="145f94b9-c68f-8050-8a54-fe553847b87c" class="">
</p><p id="145f94b9-c68f-80b9-93a7-fdb908f3e2c9" class="">Our sampling method employs classifier-free guidance to try and sample an image from a particular class. For each digit from 0 to 9, I sampled four images and displayed the results below (for epochs 5 and 20). </p><div id="145f94b9-c68f-80b7-a056-f793aecd30cd" class="column-list"><div id="145f94b9-c68f-8098-9381-e36b6386d1dc" style="width:50%" class="column"><figure id="145f94b9-c68f-8044-841c-da1c5407738b" class="image"><a href="media/class_cond_epoch_5_sample.jpg"><img style="width:331px" src="media/class_cond_epoch_5_sample.jpg"/></a><figcaption>Results for epoch 5</figcaption></figure></div><div id="145f94b9-c68f-803a-a5b2-d73c492d0387" style="width:50%" class="column"><figure id="145f94b9-c68f-8028-93d8-e0b6310c0f3e" class="image"><a href="media/class_cond_epoch_20_sample.jpg"><img style="width:708px" src="media/class_cond_epoch_20_sample.jpg"/></a><figcaption>Results for epoch 20</figcaption></figure></div></div><p id="145f94b9-c68f-8081-a9cd-ed8ddc75bf18" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>
